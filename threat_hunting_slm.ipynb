{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e651288d-f534-40ad-9a01-df4632fcad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyattck\n",
      "  Downloading pyattck-7.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting attrs<22.0.0,>=21.4.0 (from pyattck)\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting fire<0.5.0,>=0.4.0 (from pyattck)\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyattck-data<3.0.0,>=2.6.3 (from pyattck)\n",
      "  Downloading pyattck_data-2.6.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck) (2.32.3)\n",
      "Collecting rich<13.0.0,>=12.5.1 (from pyattck)\n",
      "  Downloading rich-12.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.12/site-packages (from fire<0.5.0,>=0.4.0->pyattck) (1.16.0)\n",
      "Collecting termcolor (from fire<0.5.0,>=0.4.0->pyattck)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: PyYAML<7.0,>=6.0 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck-data<3.0.0,>=2.6.3->pyattck) (6.0.2)\n",
      "Collecting importlib-metadata<3.4 (from pyattck-data<3.0.0,>=2.6.3->pyattck)\n",
      "  Downloading importlib_metadata-3.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting openpyxl<4.0.0,>=3.0.10 (from pyattck-data<3.0.0,>=2.6.3->pyattck)\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pydantic<2.0.0,>=1.9.1 (from pyattck-data<3.0.0,>=2.6.3->pyattck)\n",
      "  Downloading pydantic-1.10.19-cp312-cp312-macosx_11_0_arm64.whl.metadata (152 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (2024.7.4)\n",
      "Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.0.0,>=12.5.1->pyattck)\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from rich<13.0.0,>=12.5.1->pyattck) (2.18.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<3.4->pyattck-data<3.0.0,>=2.6.3->pyattck)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.0.10->pyattck-data<3.0.0,>=2.6.3->pyattck)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from pydantic<2.0.0,>=1.9.1->pyattck-data<3.0.0,>=2.6.3->pyattck) (4.12.2)\n",
      "Downloading pyattck-7.1.2-py3-none-any.whl (24 kB)\n",
      "Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Downloading pyattck_data-2.6.3-py3-none-any.whl (25 kB)\n",
      "Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Downloading importlib_metadata-3.3.0-py3-none-any.whl (10 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading pydantic-1.10.19-cp312-cp312-macosx_11_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115929 sha256=4b55f3e93e2b8285f7443753d6ad65ee0188a502c006e690e74e7b9f14804a85\n",
      "  Stored in directory: /Users/ibrahimmukherjee/Library/Caches/pip/wheels/2e/07/d6/a0a83630dca5ce2615bef11489b84c46692d38b393b870ec1c\n",
      "Successfully built fire\n",
      "Installing collected packages: commonmark, zipp, termcolor, rich, pydantic, et-xmlfile, attrs, openpyxl, importlib-metadata, fire, pyattck-data, pyattck\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 24.2.0\n",
      "    Uninstalling attrs-24.2.0:\n",
      "      Successfully uninstalled attrs-24.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "referencing 0.35.1 requires attrs>=22.2.0, but you have attrs 21.4.0 which is incompatible.\n",
      "jsonschema 4.23.0 requires attrs>=22.2.0, but you have attrs 21.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed attrs-21.4.0 commonmark-0.9.1 et-xmlfile-2.0.0 fire-0.4.0 importlib-metadata-3.3.0 openpyxl-3.1.5 pyattck-7.1.2 pyattck-data-2.6.3 pydantic-1.10.19 rich-12.6.0 termcolor-2.5.0 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyattck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4837989f-77d2-403a-aaa1-9e18a166c5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e9c35b-c045-4da7-9945-7e7ff613d68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d068a28-6fce-443b-8929-2ac429c28043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MITRE ATT&CK Techniques:\n",
      "                                                  id  \\\n",
      "0  attack-pattern--0042a9f5-f053-4769-b3ef-9ad018...   \n",
      "1  attack-pattern--005a06c6-14bf-4118-afa0-ebcd8a...   \n",
      "2  attack-pattern--005cc321-08ce-4d17-b1ea-cb5275...   \n",
      "3  attack-pattern--00d0b012-8a03-410e-95de-5826bf...   \n",
      "4  attack-pattern--00f90846-cbd1-4fc5-9233-df5c2b...   \n",
      "\n",
      "                            name  \\\n",
      "0  Extra Window Memory Injection   \n",
      "1                 Scheduled Task   \n",
      "2                 Socket Filters   \n",
      "3   Indicator Removal from Tools   \n",
      "4            Archive via Utility   \n",
      "\n",
      "                                         description  \n",
      "0  Adversaries may inject malicious code into pro...  \n",
      "1  Adversaries may abuse the Windows Task Schedul...  \n",
      "2  Adversaries may attach filters to a network so...  \n",
      "3  If a malicious tool is detected and quarantine...  \n",
      "4  Adversaries may use utilities to compress and/...  \n",
      "\n",
      "Synthetic Dataset:\n",
      "Training samples: 8000\n",
      "Testing samples: 2000\n",
      "\n",
      "Synthetic data sample:\n",
      "            timestamp      source_ip destination_ip   port protocol  \\\n",
      "0 2024-01-01 00:00:00  192.168.1.245     10.0.0.128  24475     ICMP   \n",
      "1 2024-01-01 01:00:00  192.168.1.109      10.0.0.86  18712      UDP   \n",
      "2 2024-01-01 02:00:00  192.168.1.125     10.0.0.216   3138      UDP   \n",
      "3 2024-01-01 03:00:00  192.168.1.196     10.0.0.176   2102     ICMP   \n",
      "4 2024-01-01 04:00:00   192.168.1.26      10.0.0.11  55660      TCP   \n",
      "\n",
      "   bytes_transferred                                       technique_id  \\\n",
      "0               7005  attack-pattern--68c96494-1a50-403e-8844-69a6af...   \n",
      "1               3873  attack-pattern--42fe883a-21ea-4cfb-b94a-78b647...   \n",
      "2               7930  attack-pattern--69b8fd78-40e8-4600-ae4d-662c9d...   \n",
      "3               6821  attack-pattern--24769ab5-14bd-4f4e-a752-cfb185...   \n",
      "4               4337  attack-pattern--6836813e-8ec8-4375-b459-abb388...   \n",
      "\n",
      "   threat  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/x7h0c_d13ndg819dhry4_2br0000gn/T/ipykernel_34962/2830092740.py:26: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  'timestamp': pd.date_range(start='2024-01-01', periods=num_samples, freq='H'),\n"
     ]
    }
   ],
   "source": [
    "from pyattck import Attck\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize MITRE ATT&CK data\n",
    "attck = Attck()\n",
    "\n",
    "# Function to extract MITRE ATT&CK techniques\n",
    "def extract_techniques():\n",
    "    techniques = []\n",
    "    for technique in attck.enterprise.techniques:\n",
    "        techniques.append({\n",
    "            'id': technique.id,\n",
    "            'name': technique.name,\n",
    "            'description': technique.description\n",
    "        })\n",
    "    return pd.DataFrame(techniques)\n",
    "\n",
    "# Function to create synthetic threat data\n",
    "def create_synthetic_threat_data(num_samples=1000):\n",
    "    techniques_df = extract_techniques()\n",
    "    \n",
    "    # Create synthetic features\n",
    "    data = {\n",
    "        'timestamp': pd.date_range(start='2024-01-01', periods=num_samples, freq='H'),\n",
    "        'source_ip': np.random.choice(['192.168.1.' + str(i) for i in range(1, 255)], num_samples),\n",
    "        'destination_ip': np.random.choice(['10.0.0.' + str(i) for i in range(1, 255)], num_samples),\n",
    "        'port': np.random.randint(1, 65536, num_samples),\n",
    "        'protocol': np.random.choice(['TCP', 'UDP', 'ICMP'], num_samples),\n",
    "        'bytes_transferred': np.random.randint(100, 10000, num_samples),\n",
    "        'technique_id': np.random.choice(techniques_df['id'], num_samples)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add a 'threat' column (1 for threat, 0 for normal)\n",
    "    df['threat'] = np.random.choice([0, 1], num_samples, p=[0.8, 0.2])  # 20% of data labeled as threats\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to process synthetic data\n",
    "def process_synthetic_data(num_samples=1000):\n",
    "    df = create_synthetic_threat_data(num_samples)\n",
    "    \n",
    "    # Split the data into features (X) and labels (y)\n",
    "    X = df.drop(['threat', 'timestamp'], axis=1)\n",
    "    y = df['threat']\n",
    "    \n",
    "    # Convert categorical variables to numeric\n",
    "    X = pd.get_dummies(X, columns=['protocol', 'technique_id'])\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, df\n",
    "\n",
    "# Main function to ingest data\n",
    "def ingest_data(num_samples=1000):\n",
    "    # Extract MITRE ATT&CK techniques\n",
    "    techniques_df = extract_techniques()\n",
    "    print(\"MITRE ATT&CK Techniques:\")\n",
    "    print(techniques_df.head())\n",
    "    \n",
    "    # Process synthetic dataset\n",
    "    X_train, y_train, X_test, y_test, synthetic_df = process_synthetic_data(num_samples)\n",
    "    print(\"\\nSynthetic Dataset:\")\n",
    "    print(f\"Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "    print(\"\\nSynthetic data sample:\")\n",
    "    print(synthetic_df.head())\n",
    "\n",
    "    return techniques_df, X_train, y_train, X_test, y_test, synthetic_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    techniques_df, X_train, y_train, X_test, y_test, synthetic_df = ingest_data(num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e637cba-95da-4f02-81c7-532b5d5288e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: pyattck in /opt/miniconda3/lib/python3.12/site-packages (7.1.2)\n",
      "Collecting faker\n",
      "  Downloading Faker-33.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: attrs<22.0.0,>=21.4.0 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck) (21.4.0)\n",
      "Requirement already satisfied: fire<0.5.0,>=0.4.0 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck) (0.4.0)\n",
      "Requirement already satisfied: pyattck-data<3.0.0,>=2.6.3 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck) (2.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck) (2.32.3)\n",
      "Requirement already satisfied: rich<13.0.0,>=12.5.1 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck) (12.6.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/miniconda3/lib/python3.12/site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.12/site-packages (from fire<0.5.0,>=0.4.0->pyattck) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/miniconda3/lib/python3.12/site-packages (from fire<0.5.0,>=0.4.0->pyattck) (2.5.0)\n",
      "Requirement already satisfied: PyYAML<7.0,>=6.0 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck-data<3.0.0,>=2.6.3->pyattck) (6.0.2)\n",
      "Requirement already satisfied: importlib-metadata<3.4 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck-data<3.0.0,>=2.6.3->pyattck) (3.3.0)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.0.10 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck-data<3.0.0,>=2.6.3->pyattck) (3.1.5)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.9.1 in /opt/miniconda3/lib/python3.12/site-packages (from pyattck-data<3.0.0,>=2.6.3->pyattck) (1.10.19)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.27.1->pyattck) (2024.7.4)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/miniconda3/lib/python3.12/site-packages (from rich<13.0.0,>=12.5.1->pyattck) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from rich<13.0.0,>=12.5.1->pyattck) (2.18.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/miniconda3/lib/python3.12/site-packages (from importlib-metadata<3.4->pyattck-data<3.0.0,>=2.6.3->pyattck) (3.21.0)\n",
      "Requirement already satisfied: et-xmlfile in /opt/miniconda3/lib/python3.12/site-packages (from openpyxl<4.0.0,>=3.0.10->pyattck-data<3.0.0,>=2.6.3->pyattck) (2.0.0)\n",
      "Downloading Faker-33.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-33.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn pyattck faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec84ff2-525a-4eff-834b-d57ef37df1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MITRE ATT&CK Techniques:\n",
      "                                                  id  \\\n",
      "0  attack-pattern--0042a9f5-f053-4769-b3ef-9ad018...   \n",
      "1  attack-pattern--005a06c6-14bf-4118-afa0-ebcd8a...   \n",
      "2  attack-pattern--005cc321-08ce-4d17-b1ea-cb5275...   \n",
      "3  attack-pattern--00d0b012-8a03-410e-95de-5826bf...   \n",
      "4  attack-pattern--00f90846-cbd1-4fc5-9233-df5c2b...   \n",
      "\n",
      "                            name  \\\n",
      "0  Extra Window Memory Injection   \n",
      "1                 Scheduled Task   \n",
      "2                 Socket Filters   \n",
      "3   Indicator Removal from Tools   \n",
      "4            Archive via Utility   \n",
      "\n",
      "                                         description  \n",
      "0  Adversaries may inject malicious code into pro...  \n",
      "1  Adversaries may abuse the Windows Task Schedul...  \n",
      "2  Adversaries may attach filters to a network so...  \n",
      "3  If a malicious tool is detected and quarantine...  \n",
      "4  Adversaries may use utilities to compress and/...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/x7h0c_d13ndg819dhry4_2br0000gn/T/ipykernel_34962/1579148534.py:26: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  'timestamp': pd.date_range(start='2024-01-01', periods=num_samples, freq='H'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced Synthetic Dataset:\n",
      "Training samples: 8000\n",
      "Testing samples: 2000\n",
      "\n",
      "Synthetic data sample:\n",
      "            timestamp        source_ip   destination_ip   port protocol  \\\n",
      "0 2024-01-01 00:00:00  179.139.118.219  150.214.148.175   4703      TCP   \n",
      "1 2024-01-01 01:00:00  130.153.140.131   194.221.16.189  18247     HTTP   \n",
      "2 2024-01-01 02:00:00   200.25.206.115   160.117.40.152  12522      TCP   \n",
      "3 2024-01-01 03:00:00    3.202.181.242    80.43.107.209  47603      UDP   \n",
      "4 2024-01-01 04:00:00    61.161.21.154   62.165.135.198  59733     HTTP   \n",
      "\n",
      "   bytes_transferred                                       technique_id  \\\n",
      "0             417719  attack-pattern--b77cf5f3-6060-475d-bd60-40ccbf...   \n",
      "1             418302  attack-pattern--fb640c43-aa6b-431e-a961-a27901...   \n",
      "2             559682  attack-pattern--40f5caa0-4cb7-4117-89fc-d421bb...   \n",
      "3             725513  attack-pattern--3f18edba-28f4-4bb9-82c3-8aa60d...   \n",
      "4             672788  attack-pattern--f44731de-ea9f-406d-9b83-30ecbb...   \n",
      "\n",
      "                                          user_agent       country_origin  \\\n",
      "0  Mozilla/5.0 (Windows CE; zh-SG; rv:1.9.0.20) G...  Antigua and Barbuda   \n",
      "1  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0...        Liechtenstein   \n",
      "2  Mozilla/5.0 (compatible; MSIE 6.0; Windows NT ...             Kiribati   \n",
      "3  Mozilla/5.0 (iPad; CPU iPad OS 6_1_6 like Mac ...            Greenland   \n",
      "4  Opera/8.56.(Windows NT 5.0; ca-IT) Presto/2.9....                Kenya   \n",
      "\n",
      "  malware_family  threat ai_generated ai_technique state_sponsored  \\\n",
      "0        Spyware       0          NaN          NaN             NaN   \n",
      "1        Rootkit       0          NaN          NaN             NaN   \n",
      "2        Rootkit       0          NaN          NaN             NaN   \n",
      "3         Botnet       0          NaN          NaN             NaN   \n",
      "4        Rootkit       0          NaN          NaN             NaN   \n",
      "\n",
      "  attributed_country  \n",
      "0                NaN  \n",
      "1                NaN  \n",
      "2                NaN  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "\n",
      "Threat Statistics:\n",
      "Total threats: 2008\n",
      "AI-generated threats: 176\n",
      "State-sponsored threats: 291\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyattck import Attck\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize MITRE ATT&CK and Faker\n",
    "attck = Attck()\n",
    "fake = Faker()\n",
    "\n",
    "def extract_techniques():\n",
    "    techniques = []\n",
    "    for technique in attck.enterprise.techniques:\n",
    "        techniques.append({\n",
    "            'id': technique.id,\n",
    "            'name': technique.name,\n",
    "            'description': technique.description\n",
    "        })\n",
    "    return pd.DataFrame(techniques)\n",
    "\n",
    "def create_advanced_synthetic_threat_data(num_samples=1000):\n",
    "    techniques_df = extract_techniques()\n",
    "    \n",
    "    # Create more diverse and realistic synthetic features\n",
    "    data = {\n",
    "        'timestamp': pd.date_range(start='2024-01-01', periods=num_samples, freq='H'),\n",
    "        'source_ip': [fake.ipv4() for _ in range(num_samples)],\n",
    "        'destination_ip': [fake.ipv4() for _ in range(num_samples)],\n",
    "        'port': np.random.randint(1, 65536, num_samples),\n",
    "        'protocol': np.random.choice(['TCP', 'UDP', 'ICMP', 'HTTP', 'HTTPS'], num_samples),\n",
    "        'bytes_transferred': np.random.randint(100, 1000000, num_samples),\n",
    "        'technique_id': np.random.choice(techniques_df['id'], num_samples),\n",
    "        'user_agent': [fake.user_agent() for _ in range(num_samples)],\n",
    "        'country_origin': [fake.country() for _ in range(num_samples)],\n",
    "        'malware_family': np.random.choice(['Ransomware', 'Trojan', 'Botnet', 'Spyware', 'Rootkit', None], num_samples),\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add more realistic threat labeling\n",
    "    df['threat'] = np.random.choice([0, 1], num_samples, p=[0.8, 0.2])  # 20% of data labeled as threats\n",
    "    \n",
    "    # Add AI-related threats\n",
    "    ai_threat_mask = (df['threat'] == 1) & (np.random.rand(num_samples) < 0.1)  # 10% of threats are AI-related\n",
    "    df.loc[ai_threat_mask, 'ai_generated'] = True\n",
    "    df.loc[ai_threat_mask, 'ai_technique'] = np.random.choice(['Deepfake', 'GAN', 'NLP Attack'], ai_threat_mask.sum())\n",
    "    \n",
    "    # Add state-sponsored actor attribution\n",
    "    state_actor_mask = (df['threat'] == 1) & (np.random.rand(num_samples) < 0.15)  # 15% of threats are state-sponsored\n",
    "    df.loc[state_actor_mask, 'state_sponsored'] = True\n",
    "    df.loc[state_actor_mask, 'attributed_country'] = np.random.choice(['North Korea', 'Russia', 'China', 'Iran'], state_actor_mask.sum())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_advanced_synthetic_data(num_samples=1000):\n",
    "    df = create_advanced_synthetic_threat_data(num_samples)\n",
    "    \n",
    "    # Split the data into features (X) and labels (y)\n",
    "    X = df.drop(['threat', 'timestamp', 'ai_generated', 'ai_technique', 'state_sponsored', 'attributed_country'], axis=1)\n",
    "    y = df['threat']\n",
    "    \n",
    "    # Convert categorical variables to numeric\n",
    "    X = pd.get_dummies(X, columns=['protocol', 'technique_id', 'country_origin', 'malware_family'])\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, df\n",
    "\n",
    "def ingest_advanced_data(num_samples=10000):\n",
    "    # Extract MITRE ATT&CK techniques\n",
    "    techniques_df = extract_techniques()\n",
    "    print(\"MITRE ATT&CK Techniques:\")\n",
    "    print(techniques_df.head())\n",
    "    \n",
    "    # Process advanced synthetic dataset\n",
    "    X_train, y_train, X_test, y_test, synthetic_df = process_advanced_synthetic_data(num_samples)\n",
    "    print(\"\\nAdvanced Synthetic Dataset:\")\n",
    "    print(f\"Training samples: {X_train.shape[0]}\")\n",
    "    print(f\"Testing samples: {X_test.shape[0]}\")\n",
    "    print(\"\\nSynthetic data sample:\")\n",
    "    print(synthetic_df.head())\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(\"\\nThreat Statistics:\")\n",
    "    print(f\"Total threats: {synthetic_df['threat'].sum()}\")\n",
    "    print(f\"AI-generated threats: {synthetic_df['ai_generated'].sum() if 'ai_generated' in synthetic_df.columns else 0}\")\n",
    "    print(f\"State-sponsored threats: {synthetic_df['state_sponsored'].sum() if 'state_sponsored' in synthetic_df.columns else 0}\")\n",
    "\n",
    "    return techniques_df, X_train, y_train, X_test, y_test, synthetic_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    techniques_df, X_train, y_train, X_test, y_test, synthetic_df = ingest_advanced_data(num_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f45441-f1b0-4bc4-a17c-46f725e04b2a",
   "metadata": {},
   "source": [
    "Steps:\n",
    "Preprocess the dataset: Extract relevant textual features (e.g., threat descriptions, attack techniques).\n",
    "Generate embeddings: Use OpenELM to convert the textual data into numerical embeddings.\n",
    "Cluster the embeddings: Apply a clustering algorithm (e.g., KMeans) to group similar threats based on their embeddings.\n",
    "Visualize the clusters: Plot the clusters to understand how different threats are grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56435450-2a9e-4dc5-ad3b-414402a5b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4217c01a-a24d-4b8a-ae54-a77f5066c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/miniconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/miniconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba1325a3-b6f8-492d-bb8d-a6fa4c7f2e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.12/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2f7998a-e8ce-4019-b6ba-d030e3e8d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/miniconda3/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cf39617-bafc-4d01-8529-363067570331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b351bad36d43a4acf8be8aa698fee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbafb3f10694b57b0cab7ee6393af09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90a1fe0640b48cfb81864d84c0cde46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a61fb9016824544a96bbe8104d0f189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "\nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load pre-trained BERT model and tokenizer\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Function to extract textual features from dataset\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_textual_features\u001b[39m(df):\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1651\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1651\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1639\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1637\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to extract textual features from dataset\n",
    "def extract_textual_features(df):\n",
    "    return df['description'].fillna('')\n",
    "\n",
    "# Function to generate embeddings using BERT\n",
    "def generate_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Function to perform clustering on embeddings\n",
    "def cluster_embeddings(embeddings, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(embeddings)\n",
    "    return clusters\n",
    "\n",
    "# Function to visualize clusters using PCA\n",
    "def visualize_clusters(embeddings, clusters):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=clusters, cmap='viridis', alpha=0.5)\n",
    "    plt.title('KMeans Clustering of Threat Data using BERT Embeddings')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.show()\n",
    "\n",
    "# Main function to process dataset and perform clustering\n",
    "def process_and_cluster_threat_data(df, n_clusters=5):\n",
    "    texts = extract_textual_features(df)\n",
    "\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = generate_embeddings(texts)\n",
    "\n",
    "    print(\"Clustering data...\")\n",
    "    clusters = cluster_embeddings(embeddings, n_clusters=n_clusters)\n",
    "\n",
    "    print(\"Visualizing clusters...\")\n",
    "    visualize_clusters(embeddings, clusters)\n",
    "\n",
    "    df['cluster'] = clusters\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    synthetic_df = pd.DataFrame({\n",
    "        'description': [\n",
    "            \"Ransomware attack detected from Russia\",\n",
    "            \"Phishing attempt using AI-generated emails\",\n",
    "            \"SQL injection attack targeting financial institution\",\n",
    "            \"DDoS attack originating from North Korea\",\n",
    "            \"Advanced persistent threat detected using GAN\",\n",
    "            \"Insider threat detected with abnormal login patterns\",\n",
    "            \"AI-powered malware spreading via social media\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    clustered_df = process_and_cluster_threat_data(synthetic_df, n_clusters=4)\n",
    "    print(clustered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316563b5-86f5-435b-8748-ae3f9ea2c85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
